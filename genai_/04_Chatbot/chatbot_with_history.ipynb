{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b13185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35620721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002104FE378E0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002104FE61B70>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faefec13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Akshay, it's nice to meet you! \\n\\nIt's great to know you're a research engineer at VizuaraAI Labs. What kind of research are you working on? I'm always interested in learning about new developments in AI.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 27, 'total_tokens': 84, 'completion_time': 0.103636364, 'prompt_time': 0.003344456, 'queue_time': 0.328542942, 'total_time': 0.10698082}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--8a8e255f-c931-4f47-85c8-0e571c4076e3-0', usage_metadata={'input_tokens': 27, 'output_tokens': 57, 'total_tokens': 84})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi, my name is Akshay and I am a research engineer at VizuaraAI Labs\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fefa4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Akshay and that you are a research engineer at VizuaraAI Labs.  \\n\\nIs there anything else you'd like to tell me about yourself or your work? I'm eager to learn more! üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 103, 'total_tokens': 155, 'completion_time': 0.094545455, 'prompt_time': 0.005432756, 'queue_time': 0.24804349299999998, 'total_time': 0.099978211}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--51e7eafc-5d7d-44a3-8972-a9ca92372c55-0', usage_metadata={'input_tokens': 103, 'output_tokens': 52, 'total_tokens': 155})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi, my name is Akshay and I am a research engineer at VizuaraAI Labs\"),\n",
    "    AIMessage(content=\"Hi Akshay, it's nice to meet you! \\n\\nIt's great to know you're a research engineer at VizuaraAI Labs. What kind of research are you working on? I'm always interested in learning about new developments in AI.\\n\"),\n",
    "    HumanMessage(content=\"Hey what's my name and and I do?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5017f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "def get_session_history(session_id: str)-> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory() \n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cba3498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config={\"configurable\":{\"session_id\": \"chat1\"}}\n",
    "\n",
    "from typing import cast\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = cast(RunnableConfig, {\"configurable\": {\"session_id\": \"chat1\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7d171c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Akshay, it's nice to meet you!\\n\\nAs a research engineer at VizuaraAI Labs, what kind of projects are you working on?\\n\\nI'm always interested in learning more about the latest advancements in AI.  Perhaps you could tell me a little about your work?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 27, 'total_tokens': 90, 'completion_time': 0.114545455, 'prompt_time': 0.00214298, 'queue_time': 0.24658459800000002, 'total_time': 0.116688435}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--ebfa4fe6-e260-42b9-bbb3-75361e211403-0', usage_metadata={'input_tokens': 27, 'output_tokens': 63, 'total_tokens': 90})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke([\n",
    "    HumanMessage(content=\"Hi, my name is Akshay and I am a research engineer at VizuaraAI Labs\")\n",
    "],\n",
    "config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b4e515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change the config-->Session id\n",
    "config1 = cast(RunnableConfig, {\"configurable\": {\"session_id\": \"chat1\"}})\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e7aa0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Akshay.  \\n\\nI remembered it from our earlier conversation! üòä  Is there anything else I can help you with?\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a61f284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"You are the helpful assistant. Answer all the questions to the best of your ability\"),\n",
    "    MessagesPlaceholder(variable_name=\"message\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bb54a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26044828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Akshay!\\n\\nIt's nice to meet you. What can I do for you today? üòä  \\n\\nI'm ready to answer your questions and help in any way I can.  \\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"message\":[HumanMessage(content=\"Hi, my name is akshay\")]})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "875e00af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed7d6341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Akshay! It's nice to meet you.  \\n\\nHow can I help you today? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 88, 'total_tokens': 113, 'completion_time': 0.045454545, 'prompt_time': 0.005442069, 'queue_time': 0.24597013099999998, 'total_time': 0.050896614}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--1a97b952-48f0-441e-9a62-26d01ca39f7e-0', usage_metadata={'input_tokens': 88, 'output_tokens': 25, 'total_tokens': 113})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2 = cast(RunnableConfig, {\"configurable\": {\"session_id\": \"chat3\"}})\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, my name is akshay\")],\n",
    "    config=config2\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "155ed84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26539400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some complexity\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"You are the helpful assistant. Answer all the questions to the best of your ability in {language}\"),\n",
    "    MessagesPlaceholder(variable_name=\"message\")\n",
    "])\n",
    "\n",
    "chain = prompt|model|parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "439f1c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§Ö‡§ï‡•ç‡§∑‡§Ø! ‡§Æ‡§≤‡§æ ‡§Æ‡§æ‡§π‡§ø‡§§ ‡§Ü‡§π‡•á ‡§ï‡•Ä ‡§§‡•Å‡§Æ‡§ö‡•á ‡§®‡§æ‡§µ ‡§Ö‡§ï‡•ç‡§∑‡§Ø ‡§Ü‡§π‡•á. ‡§Æ‡•Ä ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡§¶‡§§‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§Ø‡•á‡§•‡•á ‡§Ü‡§π‡•á. ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§ï‡§æ‡§Ø ‡§∏‡§æ‡§Ç‡§ó‡§æ‡§Ø‡§ö‡•á ‡§Ü‡§π‡•á?  üòä\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"message\":[HumanMessage(content=\"Hi my nname is akshay\")],\"language\":\"marathi\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "158ef47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain, \n",
    "    get_session_history,\n",
    "    input_messages_key=\"message\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27debfc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§Ö‡§ï‡•ç‡§∑‡§Ø! \\n\\n‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à‡•§ ‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ ‡§π‡•à, ‡§î‡§∞ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ø‡§π‡§æ‡§Å ‡§π‡•Ç‡§Å‡•§ ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? \\n\\n\\n(Namaste Akshay! \\n\\nWelcome. My name is Artificial Intelligence, and I am here to assist you. What can I help you with?) \\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config3 = cast(RunnableConfig, {\"configurable\": {\"session_id\": \"chat4\"}})\n",
    "response = with_message_history.invoke(\n",
    "    {\"message\": [HumanMessage(content=\"Hi, my name is akshay\")], \"language\": \"sanskrit\"},\n",
    "    config=config3\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b0bedf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7df6e1ac29435daa3e0c867bc1f58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Langchain\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f42f15039e49868f48b308f9f4f84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7032fabfe07540e1b9579882b7ab8d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566272afb48944409e37ecd276ea2516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391b19760a7e4d7d882d06a29da98038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"hi! I'm karan\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Mananging conversation history\n",
    "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage, trim_messages \n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm karan\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83769f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"whats 2 + 2\" üòä  \\n\\n\\n\\nLet me know if you have any other questions!\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"message\") | trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"message\": messages + [HumanMessage(content=\"What math problem did i asked?\")],\n",
    "    \"language\": \"English\"\n",
    "})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253be38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"‡§Æ‡§æ‡•û ‡§ï‡§∞‡§®‡§æ, ‡§™‡§∞‡§Ç‡§§‡•Å ‡§Æ‡•Å‡§ù‡•á ‡§Ø‡§æ‡§¶ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™‡§®‡•á ‡§ï‡•å‡§® ‡§∏‡•Ä ‡§ó‡§£‡§ø‡§§ ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡•Ä ‡§•‡•Ä‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç?\\n\\n(I'm sorry, but I don't remember what math problem you asked. Could you please ask it again?) \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 141, 'total_tokens': 205, 'completion_time': 0.116363636, 'prompt_time': 0.0132603, 'queue_time': 0.63044113, 'total_time': 0.129623936}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--a4c7dafb-1e7d-4a15-b788-a6c733b260eb-0', usage_metadata={'input_tokens': 141, 'output_tokens': 64, 'total_tokens': 205})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets wrap this message history \n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain, \n",
    "    get_session_history,\n",
    "    input_messages_key=\"message\"\n",
    ")\n",
    "\n",
    "\n",
    "config4 = cast(RunnableConfig, {\"configurable\": {\"session_id\": \"chat4\"}})\n",
    "response = with_message_history.invoke(\n",
    "    {\"message\": [HumanMessage(content=\"What math problem I aksed?\")], \"language\": \"English\"},\n",
    "    config=config4\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b513b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
