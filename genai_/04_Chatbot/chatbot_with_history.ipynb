{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b13185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35620721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002104FE378E0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002104FE61B70>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faefec13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Akshay, it's nice to meet you! \\n\\nIt's great to know you're a research engineer at VizuaraAI Labs. What kind of research are you working on? I'm always interested in learning about new developments in AI.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 27, 'total_tokens': 84, 'completion_time': 0.103636364, 'prompt_time': 0.003344456, 'queue_time': 0.328542942, 'total_time': 0.10698082}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--8a8e255f-c931-4f47-85c8-0e571c4076e3-0', usage_metadata={'input_tokens': 27, 'output_tokens': 57, 'total_tokens': 84})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi, my name is Akshay and I am a research engineer at VizuaraAI Labs\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fefa4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Akshay and that you are a research engineer at VizuaraAI Labs.  \\n\\nIs there anything else you'd like to tell me about yourself or your work? I'm eager to learn more! 😊  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 103, 'total_tokens': 155, 'completion_time': 0.094545455, 'prompt_time': 0.005432756, 'queue_time': 0.24804349299999998, 'total_time': 0.099978211}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--51e7eafc-5d7d-44a3-8972-a9ca92372c55-0', usage_metadata={'input_tokens': 103, 'output_tokens': 52, 'total_tokens': 155})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi, my name is Akshay and I am a research engineer at VizuaraAI Labs\"),\n",
    "    AIMessage(content=\"Hi Akshay, it's nice to meet you! \\n\\nIt's great to know you're a research engineer at VizuaraAI Labs. What kind of research are you working on? I'm always interested in learning about new developments in AI.\\n\"),\n",
    "    HumanMessage(content=\"Hey what's my name and and I do?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5017f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "def get_session_history(session_id: str)-> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory() \n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cba3498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config={\"configurable\":{\"session_id\": \"chat1\"}}\n",
    "\n",
    "from typing import cast\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = cast(RunnableConfig, {\"configurable\": {\"session_id\": \"chat1\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7d171c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Akshay, it's nice to meet you!\\n\\nAs a research engineer at VizuaraAI Labs, what kind of projects are you working on?\\n\\nI'm always interested in learning more about the latest advancements in AI.  Perhaps you could tell me a little about your work?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 27, 'total_tokens': 90, 'completion_time': 0.114545455, 'prompt_time': 0.00214298, 'queue_time': 0.24658459800000002, 'total_time': 0.116688435}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--ebfa4fe6-e260-42b9-bbb3-75361e211403-0', usage_metadata={'input_tokens': 27, 'output_tokens': 63, 'total_tokens': 90})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke([\n",
    "    HumanMessage(content=\"Hi, my name is Akshay and I am a research engineer at VizuaraAI Labs\")\n",
    "],\n",
    "config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b4e515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change the config-->Session id\n",
    "config1 = cast(RunnableConfig, {\"configurable\": {\"session_id\": \"chat1\"}})\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e7aa0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Akshay.  \\n\\nI remembered it from our earlier conversation! 😊  Is there anything else I can help you with?\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a61f284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"You are the helpful assistant. Answer all the questions to the best of your ability\"),\n",
    "    MessagesPlaceholder(variable_name=\"message\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bb54a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26044828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Akshay!\\n\\nIt's nice to meet you. What can I do for you today? 😊  \\n\\nI'm ready to answer your questions and help in any way I can.  \\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"message\":[HumanMessage(content=\"Hi, my name is akshay\")]})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "875e00af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed7d6341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Akshay! It's nice to meet you.  \\n\\nHow can I help you today? 😊  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 88, 'total_tokens': 113, 'completion_time': 0.045454545, 'prompt_time': 0.005442069, 'queue_time': 0.24597013099999998, 'total_time': 0.050896614}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--1a97b952-48f0-441e-9a62-26d01ca39f7e-0', usage_metadata={'input_tokens': 88, 'output_tokens': 25, 'total_tokens': 113})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2 = cast(RunnableConfig, {\"configurable\": {\"session_id\": \"chat3\"}})\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, my name is akshay\")],\n",
    "    config=config2\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "155ed84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26539400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some complexity\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"You are the helpful assistant. Answer all the questions to the best of your ability in {language}\"),\n",
    "    MessagesPlaceholder(variable_name=\"message\")\n",
    "])\n",
    "\n",
    "chain = prompt|model|parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "439f1c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्कार अक्षय! मला माहित आहे की तुमचे नाव अक्षय आहे. मी तुमच्या मदतीसाठी येथे आहे. तुम्हाला काय सांगायचे आहे?  😊\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"message\":[HumanMessage(content=\"Hi my nname is akshay\")],\"language\":\"marathi\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "158ef47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain, \n",
    "    get_session_history,\n",
    "    input_messages_key=\"message\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27debfc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते अक्षय! \\n\\nआपका स्वागत है। मेरा नाम कृत्रिम बुद्धिमत्ता है, और मैं आपकी सहायता करने के लिए यहाँ हूँ। आप मुझसे क्या जानना चाहते हैं? \\n\\n\\n(Namaste Akshay! \\n\\nWelcome. My name is Artificial Intelligence, and I am here to assist you. What can I help you with?) \\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config3 = cast(RunnableConfig, {\"configurable\": {\"session_id\": \"chat4\"}})\n",
    "response = with_message_history.invoke(\n",
    "    {\"message\": [HumanMessage(content=\"Hi, my name is akshay\")], \"language\": \"sanskrit\"},\n",
    "    config=config3\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b0bedf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7df6e1ac29435daa3e0c867bc1f58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Langchain\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f42f15039e49868f48b308f9f4f84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7032fabfe07540e1b9579882b7ab8d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566272afb48944409e37ecd276ea2516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391b19760a7e4d7d882d06a29da98038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"hi! I'm karan\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Mananging conversation history\n",
    "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage, trim_messages \n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm karan\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83769f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"whats 2 + 2\" 😊  \\n\\n\\n\\nLet me know if you have any other questions!\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"message\") | trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"message\": messages + [HumanMessage(content=\"What math problem did i asked?\")],\n",
    "    \"language\": \"English\"\n",
    "})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253be38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"माफ़ करना, परंतु मुझे याद नहीं है कि आपने कौन सी गणित समस्या पूछी थी। क्या आप कृपया फिर से पूछ सकते हैं?\\n\\n(I'm sorry, but I don't remember what math problem you asked. Could you please ask it again?) \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 141, 'total_tokens': 205, 'completion_time': 0.116363636, 'prompt_time': 0.0132603, 'queue_time': 0.63044113, 'total_time': 0.129623936}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--a4c7dafb-1e7d-4a15-b788-a6c733b260eb-0', usage_metadata={'input_tokens': 141, 'output_tokens': 64, 'total_tokens': 205})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets wrap this message history \n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain, \n",
    "    get_session_history,\n",
    "    input_messages_key=\"message\"\n",
    ")\n",
    "\n",
    "\n",
    "config4 = cast(RunnableConfig, {\"configurable\": {\"session_id\": \"chat4\"}})\n",
    "response = with_message_history.invoke(\n",
    "    {\"message\": [HumanMessage(content=\"What math problem I aksed?\")], \"language\": \"English\"},\n",
    "    config=config4\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b513b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
