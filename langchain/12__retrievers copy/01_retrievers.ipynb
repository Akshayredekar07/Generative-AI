{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7faccedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1edbcefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virat Kohli (born 5 November 1988) is an Indian international cricketer who plays ODI cricket for the India national team and is a former captain in all formats. He is a right-handed batsman and occasional right-arm medium pace bowler. Considered one of the greatest all-format batsmen in the history of cricket, he is called the King, the Chase Master, and the Run Machine for his skills, records an\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
    "\n",
    "custom_client = WikipediaAPIWrapper(lang=\"en\", top_k_results=5, wiki_client=None)\n",
    "# Create retriever (default: English, top 3 docs)\n",
    "retriever = WikipediaRetriever(wiki_client=custom_client)\n",
    "\n",
    "# Get relevant documents for a query\n",
    "docs = retriever.invoke(\"Viral Kholi\")\n",
    "print(docs[0].page_content[:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1fc037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! uv pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b0b5197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rohit Sharma is an Indian film composer, most famously known for being the music director of the film The Kashmir Files. He began his career composing music for TVCs and films, and has since worked on prominent titles in both the film and OTT spaces, including “The Kashmir Files,” “Aspirants,” and “Maharani 2.”\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "wiki = WikipediaRetriever(top_k_results=3, lang=\"en\", wiki_client=False)\n",
    "docs = wiki.invoke(\"Rohit Sharma\")\n",
    "\n",
    "llm = ChatOllama(model=\"gemma3:4b\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Answer ONLY using the context below:\\n\\n{context}\\n\\nQuestion:\\n{question}\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm \n",
    "\n",
    "response = chain.invoke({'context':docs, 'question':'\"Who is Rohit Sharma?'}) \n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d83acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab9e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Your source documents\n",
    "documents = [\n",
    "    Document(page_content=\"LangChain helps developers build LLM applications easily.\"),\n",
    "    Document(page_content=\"Chroma is a vector database optimized for LLM-based search.\"),\n",
    "    Document(page_content=\"Embeddings convert text into high-dimensional vectors.\"),\n",
    "    Document(page_content=\"OpenAI provides powerful embedding models.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f1ec197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize the embedding model\n",
    "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "# create chroma vector sotre in memory \n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"My-collection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba145fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert vectorstore into a reteriver\n",
    "retreriver = vectorstore.as_retriever(search_kwargs={\"k\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fa9ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is chroma used for?\"\n",
    "results = retreriver.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3abca2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------result1------------\n",
      "Chroma is a vector database optimized for LLM-based search.\n",
      "-----------result2------------\n",
      "Embeddings convert text into high-dimensional vectors.\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"-----------result{i+1}------------\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95a3ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain makes it easy to work with LLMs.\"),\n",
    "    Document(page_content=\"LangChain is used to build LLM based applications.\"),\n",
    "    Document(page_content=\"Chroma is used to store and search document embeddings.\"),\n",
    "    Document(page_content=\"Embeddings are vector representations of text.\"),\n",
    "    Document(page_content=\"MMR helps you get diverse results when doing similarity search.\"),\n",
    "    Document(page_content=\"LangChain supports Chroma, FAISS, Pinecone, and more.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce82e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Initialize OpenAI embeddings\n",
    "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "# Step 2: Create the FAISS vector store from documents\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0c3d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable MMR in the retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",                   # <-- This enables MMR\n",
    "    search_kwargs={\"k\": 3, \"lambda_mult\": 0.5}  # k = top results, lambda_mult = relevance-diversity balance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe567fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is langchain?\"\n",
    "results = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cad59255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "LangChain is used to build LLM based applications.\n",
      "\n",
      "--- Result 2 ---\n",
      "LangChain supports Chroma, FAISS, Pinecone, and more.\n",
      "\n",
      "--- Result 3 ---\n",
      "Embeddings are vector representations of text.\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f1fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings \n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
