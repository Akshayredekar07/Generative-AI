{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be5b917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_of_documents = [\n",
    "    \"Take a leisurely walk in the park and enjoy the fresh air.\",\n",
    "    \"Visit a local museum and discover something new.\",\n",
    "    \"Attend a live music concert and feel the rhythm.\",\n",
    "    \"Go for a hike and admire the natural scenery.\",\n",
    "    \"Have a picnic with friends and share some laughs.\",\n",
    "    \"Explore a new cuisine by dining at an ethnic restaurant.\",\n",
    "    \"Take a yoga class and stretch your body and mind.\",\n",
    "    \"Join a local sports league and enjoy some friendly competition.\",\n",
    "    \"Attend a workshop or lecture on a topic you're interested in.\",\n",
    "    \"Visit an amusement park and ride the roller coasters.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c60a160d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Take a leisurely walk in the park and enjoy the fresh air.',\n",
       " 'Visit a local museum and discover something new.',\n",
       " 'Attend a live music concert and feel the rhythm.',\n",
       " 'Go for a hike and admire the natural scenery.',\n",
       " 'Have a picnic with friends and share some laughs.',\n",
       " 'Explore a new cuisine by dining at an ethnic restaurant.',\n",
       " 'Take a yoga class and stretch your body and mind.',\n",
       " 'Join a local sports league and enjoy some friendly competition.',\n",
       " \"Attend a workshop or lecture on a topic you're interested in.\",\n",
       " 'Visit an amusement park and ride the roller coasters.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_of_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1b057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! uv pip install latexify-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7cc39a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\displaystyle \\mathrm{cosine\\_similarity}(A, B, n) = \\frac{\\sum_{i = 0}^{n - 1} \\mathopen{}\\left({A_{i} B_{i}}\\mathclose{}\\right)}{\\mathopen{}\\left( \\sum_{i = 0}^{n - 1} \\mathopen{}\\left({A_{i}^{2}}\\mathclose{}\\right) \\mathclose{}\\right)^{0.5} \\mathopen{}\\left( \\sum_{i = 0}^{n - 1} \\mathopen{}\\left({B_{i}^{2}}\\mathclose{}\\right) \\mathclose{}\\right)^{0.5}} $$"
      ],
      "text/plain": [
       "<latexify.ipython_wrappers.LatexifiedFunction at 0x24960a3fca0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import latexify\n",
    "\n",
    "@latexify.function\n",
    "def cosine_similarity(A, B, n):\n",
    "    return (\n",
    "        sum(A[i] * B[i] for i in range(n)) /\n",
    "        ((sum(A[i]**2 for i in range(n)))**0.5 * (sum(B[i]**2 for i in range(n)))**0.5)\n",
    "    )\n",
    "\n",
    "\n",
    "cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42447820",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query=\"i am an indian and i live in india\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c5a6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "document=\"india is a country for the indians and for eveyone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf597e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aff066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tokens = user_query.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b92dcc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'an', 'indian', 'and', 'i', 'live', 'in', 'india']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f6f1fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_token=document.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c908eaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['india',\n",
       " 'is',\n",
       " 'a',\n",
       " 'country',\n",
       " 'for',\n",
       " 'the',\n",
       " 'indians',\n",
       " 'and',\n",
       " 'for',\n",
       " 'eveyone']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "688cf3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'i': 2,\n",
       "         'am': 1,\n",
       "         'an': 1,\n",
       "         'indian': 1,\n",
       "         'and': 1,\n",
       "         'live': 1,\n",
       "         'in': 1,\n",
       "         'india': 1})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_counter = Counter(query_tokens)\n",
    "query_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20032c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'for': 2,\n",
       "         'india': 1,\n",
       "         'is': 1,\n",
       "         'a': 1,\n",
       "         'country': 1,\n",
       "         'the': 1,\n",
       "         'indians': 1,\n",
       "         'and': 1,\n",
       "         'eveyone': 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_counter=Counter(document_token)\n",
    "document_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca2159b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['i', 'am', 'an', 'indian', 'and', 'live', 'in', 'india'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_counter.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54ebf587",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "for token in query_counter.keys():\n",
    "    lst.append(query_counter[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f68be49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bea59f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try taking a morning yoga class with a gentle instructor to help you wake up feeling refreshed.\n",
      "\n",
      "Alternatively, consider attending a private yoga session at home with a certified teacher for personalized guidance and relaxation.\n",
      "\n",
      "You could also join a local yoga group or community center for social interaction and a sense of belonging.\n",
      "\n",
      "Lastly, look into online yoga classes or videos that cater to beginners, allowing you to practice from the comfort of your own space.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Sample corpus of documents\n",
    "corpus_of_documents = [\n",
    "    \"Take a leisurely walk in the park and enjoy the fresh air.\",\n",
    "    \"Visit a local museum and discover something new.\",\n",
    "    \"Attend a live music concert and feel the rhythm.\",\n",
    "    \"Go for a hike and admire the natural scenery.\",\n",
    "    \"Have a picnic with friends and share some laughs.\",\n",
    "    \"Explore a new cuisine by dining at an ethnic restaurant.\",\n",
    "    \"Take a yoga class and stretch your body and mind.\",\n",
    "    \"Join a local sports league and enjoy some friendly competition.\",\n",
    "    \"Attend a workshop or lecture on a topic you're interested in.\",\n",
    "    \"Visit an amusement park and ride the roller coasters.\"\n",
    "]\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Convert text to lowercase and split into tokens.\"\"\"\n",
    "    return text.lower().split()\n",
    "\n",
    "def word_frequency(tokens):\n",
    "    \"\"\"Count frequency of each token.\"\"\"\n",
    "    freq = {}\n",
    "    for token in tokens:\n",
    "        freq[token] = freq.get(token, 0) + 1\n",
    "    return freq\n",
    "\n",
    "def cosine_similarity(query, document):\n",
    "    \"\"\"Calculate cosine similarity between query and document.\"\"\"\n",
    "    query_tokens = tokenize(query)\n",
    "    doc_tokens = tokenize(document)\n",
    "    \n",
    "    query_freq = word_frequency(query_tokens)\n",
    "    doc_freq = word_frequency(doc_tokens)\n",
    "    \n",
    "    # Common tokens\n",
    "    common_tokens = set(query_freq.keys()) & set(doc_freq.keys())\n",
    "    \n",
    "    # Dot product\n",
    "    dot_product = sum(query_freq[token] * doc_freq[token] for token in common_tokens)\n",
    "    \n",
    "    # Magnitudes\n",
    "    query_magnitude = math.sqrt(sum(freq ** 2 for freq in query_freq.values()))\n",
    "    doc_magnitude = math.sqrt(sum(freq ** 2 for freq in doc_freq.values()))\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if query_magnitude * doc_magnitude == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return dot_product / (query_magnitude * doc_magnitude)\n",
    "\n",
    "def retrieve_relevant_document(query, corpus):\n",
    "    \"\"\"Retrieve the most relevant document from the corpus.\"\"\"\n",
    "    similarities = [cosine_similarity(query, doc) for doc in corpus]\n",
    "    max_similarity_idx = similarities.index(max(similarities))\n",
    "    return corpus[max_similarity_idx]\n",
    "\n",
    "def generate_response(query, relevant_document):\n",
    "    \"\"\"Generate a response using a local LLaMA model.\"\"\"\n",
    "    prompt = (\n",
    "        \"You are a bot that makes recommendations for activities. \"\n",
    "        \"Answer in short sentences. Do not include extra information. \"\n",
    "        f\"Recommended activity: {relevant_document}\\n\"\n",
    "        f\"User input: {query}\\n\"\n",
    "        \"Compile a recommendation based on the activity and user input.\"\n",
    "    )\n",
    "    \n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    data = {\n",
    "        \"model\": \"llama3.2:1b\",\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    full_response = []\n",
    "    response = None\n",
    "    try:\n",
    "        response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                decoded_line = json.loads(line.decode(\"utf-8\"))\n",
    "                full_response.append(decoded_line[\"response\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error during API call: {e}\")\n",
    "        return \"Sorry, I couldn't generate a response at this time.\"\n",
    "    finally:\n",
    "        if response:\n",
    "            response.close()\n",
    "    \n",
    "    return \"\".join(full_response)\n",
    "\n",
    "def rag_pipeline(user_query, corpus):\n",
    "    \"\"\"Main RAG pipeline: retrieve and generate.\"\"\"\n",
    "    relevant_doc = retrieve_relevant_document(user_query, corpus)\n",
    "    response = generate_response(user_query, relevant_doc)\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = \"i like to do yoga\"\n",
    "    response = rag_pipeline(user_query, corpus_of_documents)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebb6888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Sample corpus of documents\n",
    "corpus_of_documents = [\n",
    "    \"Take a leisurely walk in the park and enjoy the fresh air.\",\n",
    "    \"Visit a local museum and discover something new.\",\n",
    "    \"Attend a live music concert and feel the rhythm.\",\n",
    "    \"Go for a hike and admire the natural scenery.\",\n",
    "    \"Have a picnic with friends and share some laughs.\",\n",
    "    \"Explore a new cuisine by dining at an ethnic restaurant.\",\n",
    "    \"Take a yoga class and stretch your body and mind.\",\n",
    "    \"Join a local sports league and enjoy some friendly competition.\",\n",
    "    \"Attend a workshop or lecture on a topic you're interested in.\",\n",
    "    \"Visit an amusement park and ride the roller coasters.\"\n",
    "]\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Convert text to lowercase and split into tokens.\"\"\"\n",
    "    # Dry Run: For input \"i like to do yoga\"\n",
    "    # text.lower() -> \"i like to do yoga\"\n",
    "    # text.lower().split() -> ['i', 'like', 'to', 'do', 'yoga']\n",
    "    return text.lower().split()\n",
    "\n",
    "def word_frequency(tokens):\n",
    "    \"\"\"Count frequency of each token.\"\"\"\n",
    "    # Dry Run: For tokens = ['i', 'like', 'to', 'do', 'yoga']\n",
    "    # Initialize empty dict: freq = {}\n",
    "    # Loop: freq = {'i': 1, 'like': 1, 'to': 1, 'do': 1, 'yoga': 1}\n",
    "    freq = {}\n",
    "    for token in tokens:\n",
    "        freq[token] = freq.get(token, 0) + 1\n",
    "    return freq\n",
    "\n",
    "def cosine_similarity(query, document):\n",
    "    \"\"\"Calculate cosine similarity between query and document.\"\"\"\n",
    "    # Dry Run: query = \"i like to do yoga\", document = \"Take a yoga class and stretch your body and mind.\"\n",
    "    query_tokens = tokenize(query)\n",
    "    # query_tokens = ['i', 'like', 'to', 'do', 'yoga']\n",
    "    doc_tokens = tokenize(document)\n",
    "    # doc_tokens = ['take', 'a', 'yoga', 'class', 'and', 'stretch', 'your', 'body', 'and', 'mind']\n",
    "    \n",
    "    query_freq = word_frequency(query_tokens)\n",
    "    # query_freq = {'i': 1, 'like': 1, 'to': 1, 'do': 1, 'yoga': 1}\n",
    "    doc_freq = word_frequency(doc_tokens)\n",
    "    # doc_freq = {'take': 1, 'a': 1, 'yoga': 1, 'class': 1, 'and': 2, 'stretch': 1, 'your': 1, 'body': 1, 'mind': 1}\n",
    "    \n",
    "    common_tokens = set(query_freq.keys()) & set(doc_freq.keys())\n",
    "    # common_tokens = {'yoga'} (assuming 'to' may not match exactly)\n",
    "    \n",
    "    dot_product = sum(query_freq[token] * doc_freq[token] for token in common_tokens)\n",
    "    # dot_product = 1 * 1 = 1 (for 'yoga')\n",
    "    \n",
    "    query_magnitude = math.sqrt(sum(freq ** 2 for freq in query_freq.values()))\n",
    "    # query_magnitude = sqrt(1^2 + 1^2 + 1^2 + 1^2 + 1^2) = sqrt(5) ≈ 2.236\n",
    "    doc_magnitude = math.sqrt(sum(freq ** 2 for freq in doc_freq.values()))\n",
    "    # doc_magnitude = sqrt(1^2 + 1^2 + 1^2 + 1^2 + 2^2 + 1^2 + 1^2 + 1^2 + 1^2) = sqrt(11) ≈ 3.317\n",
    "    \n",
    "    if query_magnitude * doc_magnitude == 0:\n",
    "        return 0.0\n",
    "    return dot_product / (query_magnitude * doc_magnitude)\n",
    "    # similarity = 1 / (2.236 * 3.317) ≈ 0.135\n",
    "\n",
    "def retrieve_relevant_document(query, corpus):\n",
    "    \"\"\"Retrieve the most relevant document from the corpus.\"\"\"\n",
    "    # Dry Run: query = \"i like to do yoga\", corpus = [doc1, doc2, ..., doc7, ...]\n",
    "    similarities = [cosine_similarity(query, doc) for doc in corpus]\n",
    "    # similarities = [sim_doc1, sim_doc2, ..., 0.135 (doc7), ...]\n",
    "    # doc7 (\"Take a yoga class...\") has highest similarity due to 'yoga'\n",
    "    max_similarity_idx = similarities.index(max(similarities))\n",
    "    # max_similarity_idx = 6\n",
    "    return corpus[max_similarity_idx]\n",
    "    # Returns: \"Take a yoga class and stretch your body and mind.\"\n",
    "\n",
    "def generate_response(query, relevant_document):\n",
    "    \"\"\"Generate a response using a local LLaMA model.\"\"\"\n",
    "    # Dry Run: query = \"i like to do yoga\", relevant_document = \"Take a yoga class and stretch your body and mind.\"\n",
    "    prompt = (\n",
    "        \"You are a bot that makes recommendations for activities. \"\n",
    "        \"Answer in short sentences. Do not include extra information. \"\n",
    "        f\"Recommended activity: {relevant_document}\\n\"\n",
    "        f\"User input: {query}\\n\"\n",
    "        \"Compile a recommendation based on the activity and user input.\"\n",
    "    )\n",
    "    # prompt = \"You are a bot... Recommended activity: Take a yoga class... User input: i like to do yoga...\"\n",
    "\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    data = {\n",
    "        # \"model\": \"llama3.2:1b\",\n",
    "        # \"model\": \"deepseek-r1:1.5b\",\n",
    "        \"model\": \"gemma3:4b\",\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    full_response = []\n",
    "    response = None  # Initialize response to None to avoid UnboundLocalError\n",
    "    try:\n",
    "        response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)\n",
    "        # Dry Run: Sends POST request to local LLaMA model\n",
    "        # Assume response streams tokens: \"Great!\", \"Try\", \"a\", \"yoga\", ...\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"API request failed with status {response.status_code}\")\n",
    "        \n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                decoded_line = json.loads(line.decode(\"utf-8\"))\n",
    "                full_response.append(decoded_line[\"response\"])\n",
    "                # full_response = [\"Great!\", \"Try\", \"a\", ...]\n",
    "    except Exception as e:\n",
    "        # Dry Run: If request fails (e.g., server down), return error message\n",
    "        return f\"Error generating response: {str(e)}\"\n",
    "    finally:\n",
    "        # Only call close() if response was assigned\n",
    "        if response is not None:\n",
    "            response.close()\n",
    "    \n",
    "    return \"\".join(full_response)\n",
    "    # Returns: \"Great! Try a yoga class to stretch your body and mind.\"\n",
    "\n",
    "def rag_pipeline(user_query, corpus):\n",
    "    \"\"\"Main RAG pipeline: retrieve and generate.\"\"\"\n",
    "    # Dry Run: user_query = \"i like to do yoga\"\n",
    "    relevant_doc = retrieve_relevant_document(user_query, corpus)\n",
    "    # relevant_doc = \"Take a yoga class and stretch your body and mind.\"\n",
    "    response = generate_response(user_query, relevant_doc)\n",
    "    # response = \"Great! Try a yoga class to stretch your body and mind.\"\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = \"i like to do yoga\"\n",
    "    response = rag_pipeline(user_query, corpus_of_documents)\n",
    "    print(response)\n",
    "    # Output: \"Great! Try a yoga class to stretch your body and mind.\"\n",
    "    # If API fails: \"Error generating response: ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a9f9a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       ID              SIZE      MODIFIED    \n",
      "deepseek-r1:1.5b           e0979632db5a    1.1 GB    9 days ago     \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    2 weeks ago    \n",
      "llama3.2:1b                baf6a787fdff    1.3 GB    2 weeks ago    \n"
     ]
    }
   ],
   "source": [
    "! ollama list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
